{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://mle_20240325_54955bf804:6e3f607018b444f69359510efb12da90@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_mle_20240325_54955bf804\n",
      "Данные загружены\n",
      "               id begin_date   end_date            type paperless_billing   \n",
      "customer_id                                                                 \n",
      "8191-XWSZG      1 2015-10-01        NaT        One year                No  \\\n",
      "3957-SQXML      2 2017-04-01        NaT        Two year                No   \n",
      "6837-BJYDQ      3 2019-11-01        NaT        One year                No   \n",
      "0486-LGCCH      4 2019-03-01        NaT        Two year                No   \n",
      "7590-VHVEG      5 2020-01-01        NaT  Month-to-month               Yes   \n",
      "...           ...        ...        ...             ...               ...   \n",
      "2823-LKABH   7015 2018-08-01        NaT  Month-to-month               Yes   \n",
      "8775-CEBBJ   7016 2019-02-01 2019-11-01  Month-to-month               Yes   \n",
      "0550-DCXLH   7017 2019-01-01        NaT  Month-to-month                No   \n",
      "9281-CEDRU   7018 2014-06-01        NaT        Two year                No   \n",
      "2235-DWLJU   7019 2019-08-01        NaT  Month-to-month               Yes   \n",
      "\n",
      "                        payment_method  monthly_charges  total_charges   \n",
      "customer_id                                                              \n",
      "8191-XWSZG                Mailed check            20.65        1022.95  \\\n",
      "3957-SQXML     Credit card (automatic)            24.95         894.30   \n",
      "6837-BJYDQ                Mailed check            19.60          61.35   \n",
      "0486-LGCCH                Mailed check            19.65         225.75   \n",
      "7590-VHVEG            Electronic check            29.85          29.85   \n",
      "...                                ...              ...            ...   \n",
      "2823-LKABH   Bank transfer (automatic)            95.05        1679.40   \n",
      "8775-CEBBJ   Bank transfer (automatic)            44.20         403.35   \n",
      "0550-DCXLH                Mailed check            73.35         931.55   \n",
      "9281-CEDRU   Bank transfer (automatic)            64.10        4326.25   \n",
      "2235-DWLJU            Electronic check            44.40         263.05   \n",
      "\n",
      "            internet_service online_security online_backup device_protection   \n",
      "customer_id                                                                    \n",
      "8191-XWSZG       Fiber optic              No            No                No  \\\n",
      "3957-SQXML       Fiber optic              No            No                No   \n",
      "6837-BJYDQ       Fiber optic              No            No                No   \n",
      "0486-LGCCH       Fiber optic              No            No                No   \n",
      "7590-VHVEG               DSL              No           Yes                No   \n",
      "...                      ...             ...           ...               ...   \n",
      "2823-LKABH       Fiber optic              No            No               Yes   \n",
      "8775-CEBBJ               DSL              No            No                No   \n",
      "0550-DCXLH               DSL              No           Yes                No   \n",
      "9281-CEDRU               DSL              No           Yes                No   \n",
      "2235-DWLJU               DSL              No            No                No   \n",
      "\n",
      "            tech_support streaming_tv streaming_movies  gender   \n",
      "customer_id                                                      \n",
      "8191-XWSZG            No           No               No  Female  \\\n",
      "3957-SQXML            No           No               No  Female   \n",
      "6837-BJYDQ            No           No               No    Male   \n",
      "0486-LGCCH            No           No               No    Male   \n",
      "7590-VHVEG            No           No               No  Female   \n",
      "...                  ...          ...              ...     ...   \n",
      "2823-LKABH           Yes           No              Yes  Female   \n",
      "8775-CEBBJ            No           No               No  Female   \n",
      "0550-DCXLH           Yes          Yes              Yes    Male   \n",
      "9281-CEDRU           Yes          Yes               No  Female   \n",
      "2235-DWLJU            No          Yes              Yes  Female   \n",
      "\n",
      "             senior_citizen partner dependents multiple_lines  target  \n",
      "customer_id                                                            \n",
      "8191-XWSZG                0      No         No             No       0  \n",
      "3957-SQXML                0     Yes        Yes            Yes       0  \n",
      "6837-BJYDQ                0      No         No             No       0  \n",
      "0486-LGCCH                0     Yes        Yes             No       0  \n",
      "7590-VHVEG                0     Yes         No             No       0  \n",
      "...                     ...     ...        ...            ...     ...  \n",
      "2823-LKABH                0      No         No            Yes       0  \n",
      "8775-CEBBJ                0      No         No             No       1  \n",
      "0550-DCXLH                0      No         No             No       0  \n",
      "9281-CEDRU                0     Yes         No             No       0  \n",
      "2235-DWLJU                1      No         No             No       0  \n",
      "\n",
      "[7019 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Обучим новую модель.\n",
    "# Шаг 1. Загружаем очищенные данные из таблицы clean_users_churn\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def create_connection():\n",
    "\n",
    "    load_dotenv()\n",
    "    host = os.environ.get('DB_DESTINATION_HOST')\n",
    "    port = os.environ.get('DB_DESTINATION_PORT')\n",
    "    db = os.environ.get('DB_DESTINATION_NAME')\n",
    "    username = os.environ.get('DB_DESTINATION_USER')\n",
    "    password = os.environ.get('DB_DESTINATION_PASSWORD')\n",
    "    \n",
    "    print(f'postgresql://{username}:{password}@{host}:{port}/{db}')\n",
    "    conn = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{db}', connect_args={'sslmode':'require'})\n",
    "    return conn\n",
    "\n",
    "def get_data():\n",
    "    with open('params.yaml', 'r') as fd:\n",
    "        params = yaml.safe_load(fd)\n",
    "\n",
    "    conn = create_connection()\n",
    "    data = pd.read_sql('select * from clean_users_churn', conn, index_col=params['index_col'])\n",
    "    conn.dispose()\n",
    "\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    data.to_csv('data/initial_data.csv', index=None)\n",
    "\n",
    "    print(\"Данные загружены\")\n",
    "    print(data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены\n",
      "X_train: (4913, 19), X_test: (2106, 19),y_train: (4913,), y_test: (2106,)\n",
      "Модель обучена и сохранена\n"
     ]
    }
   ],
   "source": [
    "# Шаг 2. Обучаем новую модель\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import (OneHotEncoder, SplineTransformer, \n",
    "    QuantileTransformer, RobustScaler,PolynomialFeatures,KBinsDiscretizer)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "with open('params.yaml', 'r') as fd:\n",
    "    params = yaml.safe_load(fd)\n",
    "\n",
    "data = pd.read_csv('data/initial_data.csv')\n",
    "\n",
    "X = data.drop(columns=[params['target_col'], 'end_date']) # Признаки без утечек\n",
    "y = data[params['target_col']] # Целевая переменная\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Данные разделены\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape},y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "cat_columns = [\"type\", \"payment_method\", \"internet_service\", \"gender\"]\n",
    "bin_columns = [\"paperless_billing\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "                \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"senior_citizen\",\n",
    "                \"partner\", \"dependents\", \"multiple_lines\"]\n",
    "num_columns = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "encoder_oh = OneHotEncoder(\n",
    "categories='auto',\n",
    "handle_unknown='ignore',\n",
    "max_categories=10,\n",
    "sparse_output=False,\n",
    "drop='first'\n",
    ")\n",
    "\n",
    "encoder_spl = SplineTransformer(n_knots=3, degree=4)\n",
    "encoder_q = QuantileTransformer(n_quantiles=100)\n",
    "encoder_rb = RobustScaler()\n",
    "encoder_pol = PolynomialFeatures(degree=3)\n",
    "encoder_kbd = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform', subsample=None)\n",
    "\n",
    "numeric_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('spl', encoder_spl, num_columns),\n",
    "        ('q', encoder_q, num_columns),\n",
    "        ('rb', encoder_rb, num_columns),\n",
    "        ('pol', encoder_pol, num_columns),\n",
    "        ('kbd', encoder_kbd, num_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('encoder', encoder_oh)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_columns),\n",
    "        ('cat', categorical_transformer, cat_columns + bin_columns)\n",
    "        ], \n",
    "    n_jobs=-1)\n",
    "\n",
    "\n",
    "model = LogisticRegression(C=params['C'], penalty=params['penalty'], max_iter=200)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "with open('models/fitted_model.pkl', 'wb') as fd:\n",
    "    joblib.dump(pipeline, fd)\n",
    "\n",
    "print(\"Модель обучена и сохранена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены\n",
      "Предсказания получены\n",
      "[0 0 0 ... 0 0 0]\n",
      "Количество 0: 2106\n",
      "Количество 1: 0\n",
      "[0.49574716 0.4971613  0.49915886 ... 0.48415099 0.47933361 0.4636907 ]\n",
      "{'err1': 0.0, 'err2': 0.0, 'auc': 0.6125046847950886, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'logloss': 0.6173206426093819}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-mlflow/.venv_mle_mlflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Шаг 3. Считаем метрики\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import yaml\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "with open('params.yaml', 'r') as fd:\n",
    "    params = yaml.safe_load(fd)\n",
    "\n",
    "with open('models/fitted_model.pkl', 'rb') as fd:\n",
    "    model = joblib.load(fd)\n",
    "\n",
    "data = pd.read_csv('data/initial_data.csv')\n",
    "\n",
    "X = data.drop(columns=[params['target_col'], 'end_date']) # Признаки без утечек\n",
    "y = data[params['target_col']] # Целевая переменная\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Данные разделены\")\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "print(\"Предсказания получены\")\n",
    "print(prediction)\n",
    "# Подсчет количества 1 и 0 в предсказаниях\n",
    "binary_predictions = (prediction > 0.5).astype(int)\n",
    "count_zeros = np.sum(binary_predictions == 0)\n",
    "count_ones = np.sum(binary_predictions == 1)\n",
    "print(f\"Количество 0: {count_zeros}\")\n",
    "print(f\"Количество 1: {count_ones}\")\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "print(probas)\n",
    "\n",
    "# Заводим словарь для хранения метрик\n",
    "metrics = {}\n",
    "\n",
    "# Подсчитываем матрицу ошибок (конфузионную матрицу)\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "\n",
    "# Подсчитываем метрики\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, probas)\n",
    "\n",
    "# Записываем значения метрик в словарь\n",
    "metrics[\"err1\"] = err1\n",
    "metrics[\"err2\"] = err2\n",
    "metrics[\"auc\"] = auc\n",
    "metrics[\"precision\"] = precision\n",
    "metrics[\"recall\"] = recall\n",
    "metrics[\"f1\"] = f1\n",
    "metrics[\"logloss\"] = logloss\n",
    "\n",
    "# Выводим метрики\n",
    "print(metrics)\n",
    "\n",
    "for key, value in metrics.items():\n",
    "        metrics[key] = round(value.mean(), 3) \n",
    "\n",
    "os.makedirs('cv_results', exist_ok=True)\n",
    "with open('cv_results/cv_res.json', 'w') as fd:\n",
    "    json.dump(metrics, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-mlflow/.venv_mle_mlflow/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Registered model 'churn_model_krosh_2' already exists. Creating a new version of this model...\n",
      "2024/07/24 07:17:33 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: churn_model_krosh_2, version 3\n",
      "Created version '3' of model 'churn_model_krosh_2'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "EXPERIMENT_NAME = \"krosh_exp_21_07\"\n",
    "RUN_NAME = \"preprocrssing\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_krosh_2\"\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "pip_requirements = \"../requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:2]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    metrics = {\n",
    "        \"err1\": err1,\n",
    "        \"err2\": err2,\n",
    "        \"auc\": auc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"logloss\": logloss\n",
    "    }\n",
    "    \n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "    \n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "    sk_model=model,\n",
    "    await_registration_for=60,\n",
    "    signature=signature,\n",
    "    input_example=input_example,\n",
    "    metadata=metadata,\n",
    "    pip_requirements=pip_requirements,\n",
    "    registered_model_name=REGISTRY_MODEL_NAME,\n",
    "    artifact_path=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3057330f7f8941bebe88119191f2a873\n"
     ]
    }
   ],
   "source": [
    "print(run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle_mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
